<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <!-- <link rel="icon" href="../../favicon.ico"> -->

    <title>Testing testing!</title>

    <!-- Bootstrap core CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">

    <!-- Custom styles for this template -->
    <link href="css/starter-template.css" rel="stylesheet">

  </head>

  <body>

    <!--<div class="pyp-template"> load_file('gen/navbar.html') </div> -->

    <div class="container">
      <a name="top"></a>
      <div class="starter-template">
        <a name="about"></a>
        <h1> Justin Fu </h1>
        <h3>TODO - formatting</h3>
        <h3>TODO - picture</h3>
        I am currently a Masters student in the <a href='http://www.cs.stanford.edu/'>CS department</a> at <a href='https://www.stanford.edu/'>Stanford University</a>. Before that, I completed my undergraduate degree in <a href='http://www.eecs.berkeley.edu/'>EECS</a> at <a href='http://www.berkeley.edu/'>UC Berkeley</a>, under the supervision of professor <a href='http://www.cs.berkeley.edu/~pabbeel/'>Pieter Abbeel</a>.

        <a name="pubs"></a>
        <hr>
        <h3> Publications </h3>
        <hr>

        <div class="pyp-template"> 
            project_template(
                title="One-Shot Learning of Manipulation Skills with Online Dynamics Adaptation and Neural Network Priors",
                venues= [("NIPS 2015 Deep Reinforcement Learning Workshop", "http://rll.berkeley.edu/deeprlworkshop/"),
                        ("Under review for conference publication", None)],
                authors=["Justin Fu", "Sergey Levine", "Pieter Abbeel"],
                image="res/onlinec_thumb.png",
                description="One of the key challenges in applying reinforcement learning to complex robotic control tasks is the need to gather large amounts of experience in order to find an effective policy for the task at hand. Model-based reinforcement learning can achieve good sample efficiency, but requires the ability to learn a model of the dynamics that is good enough to learn an effective policy. In this work, we develop a model-based reinforcement learning algorithm that combines prior knowledge from previous tasks with online adaptation of the dynamics model. We encode the prior experience into a neural network dynamics model, and adapt it online by progressively refitting a local linear model of the dynamics.",
                links=[("Website", "http://rll.berkeley.edu/icra2016onlinecontrol/"),
                       ("Video", "https://www.youtube.com/watch?v=P6DZorL6Oow"),
                       ("PDF", "http://arxiv.org/pdf/1509.06841v1.pdf")
                ]
            )
        </div>

        <a name="projects"></a>
        <hr>
        <h3> Projects </h3>
        <hr>

        <div class="pyp-template"> 
            project_template(
                title="Robust Object Pose Tracking for Robotics",
                venues=[("CS280 (Computer Vision)", None)],
                image="res/cs280_thumb.png",
                authors=["Chelsea Finn", "Justin Fu", "Nopphon Siranart"],
                description="We propose a neural network based approach for visual 3D object tracking, a task important for applications such as robotic manipulation and video scene understanding. We experiment with different architectures (recurrent and feedforward) and artificial data augmentation (occlusions, background, and lighting variation) to improve prediction accuracy. We also experiment with batch normalization, a technique used to both regularize and speed up neural network training.",
                links=[
                       ("Writeup", "res/cs280_project.pdf")
                ]
            )
        </div>
        <hr>
        <div class="pyp-template"> 
            project_template(
                title="Gesture Recognition from Accelerometer Data with Recurrent Neural Networks",
                venues=[("VS265 (Neural Computation)", None)],
                image="res/vs265_thumb.png",
                authors=["Justin Fu", "Siddartho Bhattacharya"],
                description=LOREM_IPSUM,
                links=[("Code", "https://github.com/justinjfu/vs265_lstm"),
                       ("Writeup", "res/vs265_project.pdf")
                ]
            )
        </div>
        <hr>
        <div class="pyp-template"> 
            project_template(
                title="Baxter drawing",
                venues=[("EE125 (Introduction to Robotics)", None)],
                authors=["Justin Fu", "Hong Joo Kim", "Sara Seacat"],
                description=LOREM_IPSUM,
                links=[("Code", "https://github.com/justinjfu/renoir"),
                       ("Writeup", "https://sites.google.com/site/robotrenoir/")
                ]
            )
        </div>

        <a name="code"></a>
        <hr>
        <h3> Code </h3>
        <hr>

        <a href='https://github.com/cbfinn/gps'>GPS</a> - A library for deep reinforcement learning (primarily based on guided policy search).
        
      </div>

    </div><!-- /.container -->

    <a name="bottom"></a>
    <div class="bottom_section">
        <div class="container">
            <div class="row">
            </div>
        </div>
    </div>


    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.1/jquery.min.js"></script>
    <!-- <script src="//maxcdn.bootstrapcdn.com/bootstrap/3.2.0/js/bootstrap.min.js"></script> -->
    <script src="js/starter.js"></script>
  </body>
</html>
